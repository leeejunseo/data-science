#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë°œì‚¬ê° ê·¸ë£¹ ë‹¨ìœ„ í‰ê°€ (GroupShuffleSplit)
==========================================

ëª©ì :
- train_large.pyê°€ ì €ì¥í•œ dataset_large.npz ë¡œë“œ
- nominal_angle ê·¸ë£¹ ë‹¨ìœ„ë¡œ train/test ë¶„ë¦¬ (ê°ë„ ëˆ„ìˆ˜ ë°©ì§€)
- RandomForest í•™ìŠµ ë° í‰ê°€
- í˜¼ë™í–‰ë ¬/ë¶„ë¥˜ë¦¬í¬íŠ¸/ì •í™•ë„ ì¶œë ¥
- feature_importances_ ê¸°ë°˜ ì¤‘ìš” ì‹œê·¸ë‹ˆì²˜ TOP10 ì¶œë ¥
- í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©ëœ nominal_angle ëª©ë¡ ì¶œë ¥

ì‹¤í–‰:
    python eval_by_angle.py

ì…ë ¥:
    - signature_dataset/dataset_large.npz (train_large.pyê°€ ìƒì„±)

ì¶œë ¥:
    - ì½˜ì†”ì— í‰ê°€ ê²°ê³¼ ì¶œë ¥
"""

import sys
import os
import io

# Windows ì½˜ì†” ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

from pathlib import Path

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))

import numpy as np
import warnings
warnings.filterwarnings('ignore')

# sklearn
from sklearn.model_selection import GroupShuffleSplit
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import joblib


# =============================================================================
# ì„¤ì •
# =============================================================================

DATASET_FILE = Path("signature_dataset") / "dataset_large.npz"


# =============================================================================
# ë©”ì¸ í•¨ìˆ˜
# =============================================================================

def main():
    print("\n" + "=" * 70)
    print("ğŸ¯ ë°œì‚¬ê° ê·¸ë£¹ ë‹¨ìœ„ í‰ê°€ (GroupShuffleSplit)")
    print("=" * 70)
    
    # ---------------------------------------------------------------------
    # 1. ë°ì´í„°ì…‹ ë¡œë“œ
    # ---------------------------------------------------------------------
    print("\n" + "=" * 70)
    print("ğŸ“‚ STEP 1: ë°ì´í„°ì…‹ ë¡œë“œ")
    print("=" * 70)
    
    if not DATASET_FILE.exists():
        print(f"âŒ ë°ì´í„°ì…‹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {DATASET_FILE}")
        print("   ë¨¼ì € train_large.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return 1
    
    data = np.load(DATASET_FILE, allow_pickle=True)
    
    features = data['features']
    labels = data['labels']
    feature_names = list(data['feature_names'])
    missile_types = list(data['missile_types'])
    nominal_angles = data['nominal_angles']
    
    print(f"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ:")
    print(f"   X.shape: {features.shape}")
    print(f"   ì´ ìƒ˜í”Œ ìˆ˜: {len(features)}")
    print(f"   íŠ¹ì„± ìˆ˜: {len(feature_names)}")
    print(f"   ë¯¸ì‚¬ì¼ íƒ€ì…: {missile_types}")
    print(f"   ë°œì‚¬ê° ë²”ìœ„: {nominal_angles.min():.0f}Â°~{nominal_angles.max():.0f}Â°")
    print(f"   ê³ ìœ  ë°œì‚¬ê° ìˆ˜: {len(np.unique(nominal_angles))}")
    
    # ---------------------------------------------------------------------
    # 2. GroupShuffleSplitìœ¼ë¡œ ë°ì´í„° ë¶„í• 
    # ---------------------------------------------------------------------
    print("\n" + "=" * 70)
    print("ğŸ“Š STEP 2: GroupShuffleSplit (ë°œì‚¬ê° ê·¸ë£¹ ë‹¨ìœ„ ë¶„í• )")
    print("=" * 70)
    
    # groups = nominal_angle
    groups = nominal_angles.astype(int)
    
    gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
    
    for train_idx, test_idx in gss.split(features, labels, groups):
        X_train, X_test = features[train_idx], features[test_idx]
        y_train, y_test = labels[train_idx], labels[test_idx]
        groups_train = groups[train_idx]
        groups_test = groups[test_idx]
    
    # í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©ëœ ë°œì‚¬ê°
    test_angles = np.unique(groups_test)
    train_angles = np.unique(groups_train)
    
    print(f"  Train: {len(X_train)} ìƒ˜í”Œ, {len(train_angles)} ë°œì‚¬ê° ê·¸ë£¹")
    print(f"  Test: {len(X_test)} ìƒ˜í”Œ, {len(test_angles)} ë°œì‚¬ê° ê·¸ë£¹")
    
    print(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©ëœ nominal_angle ëª©ë¡:")
    print(f"   {sorted(test_angles.tolist())}Â°")
    
    print(f"\nğŸ“‹ í›ˆë ¨ì— ì‚¬ìš©ëœ nominal_angle ëª©ë¡:")
    print(f"   {sorted(train_angles.tolist())}Â°")
    
    # ë°œì‚¬ê° ê²¹ì¹¨ í™•ì¸
    overlap = set(train_angles) & set(test_angles)
    if overlap:
        print(f"\nâš ï¸ ê²½ê³ : train/test ë°œì‚¬ê° ê²¹ì¹¨ ë°œìƒ: {overlap}")
    else:
        print(f"\nâœ… train/test ë°œì‚¬ê° ì™„ì „ ë¶„ë¦¬ í™•ì¸ë¨ (ëˆ„ìˆ˜ ì—†ìŒ)")
    
    # ---------------------------------------------------------------------
    # 3. ì •ê·œí™” ë° í•™ìŠµ
    # ---------------------------------------------------------------------
    print("\n" + "=" * 70)
    print("ğŸ¤– STEP 3: RandomForest í•™ìŠµ")
    print("=" * 70)
    
    # ì •ê·œí™”
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # RandomForest í•™ìŠµ
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=15,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42,
        n_jobs=-1
    )
    
    print("ğŸ¯ í•™ìŠµ ì¤‘...")
    model.fit(X_train_scaled, y_train)
    
    # ì˜ˆì¸¡
    y_pred = model.predict(X_test_scaled)
    
    # ---------------------------------------------------------------------
    # 4. ê²°ê³¼ ì¶œë ¥
    # ---------------------------------------------------------------------
    print("\n" + "=" * 70)
    print("ğŸ“Š STEP 4: ë¶„ë¥˜ ê²°ê³¼ (ë°œì‚¬ê° ê·¸ë£¹ í‰ê°€)")
    print("=" * 70)
    
    # ì •í™•ë„
    accuracy = accuracy_score(y_test, y_pred)
    print(f"\nâœ… ì •í™•ë„ (Accuracy): {accuracy * 100:.2f}%")
    
    # Classification Report
    print("\nğŸ“‹ Classification Report:")
    print("-" * 50)
    print(classification_report(y_test, y_pred, target_names=missile_types))
    
    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    print("ğŸ“Š Confusion Matrix:")
    print("-" * 50)
    print(f"{'':>12}", end="")
    for m in missile_types:
        print(f"{m:>10}", end="")
    print()
    for i, m in enumerate(missile_types):
        print(f"{m:>12}", end="")
        for j in range(len(missile_types)):
            print(f"{cm[i, j]:>10}", end="")
        print()
    
    # ---------------------------------------------------------------------
    # 5. Feature Importance TOP10
    # ---------------------------------------------------------------------
    print("\n" + "=" * 70)
    print("ğŸ” STEP 5: ì¤‘ìš” ì‹œê·¸ë‹ˆì²˜ TOP10 (ë°œì‚¬ê° ê·¸ë£¹ í‰ê°€)")
    print("=" * 70)
    
    importances = model.feature_importances_
    feature_importance_dict = dict(zip(feature_names, importances))
    
    sorted_features = sorted(
        feature_importance_dict.items(),
        key=lambda x: x[1],
        reverse=True
    )[:10]
    
    print("\nìˆœìœ„  Feature Name                    Importance")
    print("-" * 55)
    for rank, (name, score) in enumerate(sorted_features, 1):
        print(f"{rank:>3}.  {name:<30}  {score:.6f}")
    
    # ---------------------------------------------------------------------
    # 6. ë¯¸ì‚¬ì¼ íƒ€ì…ë³„ ì„±ëŠ¥ ë¶„ì„
    # ---------------------------------------------------------------------
    print("\n" + "=" * 70)
    print("ğŸ“ˆ STEP 6: ë¯¸ì‚¬ì¼ íƒ€ì…ë³„ ì„±ëŠ¥ ë¶„ì„")
    print("=" * 70)
    
    for i, m_type in enumerate(missile_types):
        mask = y_test == i
        if mask.sum() > 0:
            type_acc = (y_pred[mask] == y_test[mask]).mean() * 100
            print(f"  {m_type}: {type_acc:.1f}% ({mask.sum()} ìƒ˜í”Œ)")
    
    # ---------------------------------------------------------------------
    # ìµœì¢… ìš”ì•½
    # ---------------------------------------------------------------------
    print("\n" + "=" * 70)
    print("âœ… ë°œì‚¬ê° ê·¸ë£¹ í‰ê°€ ì™„ë£Œ")
    print("=" * 70)
    print(f"""
  ğŸ“Š í‰ê°€ ì„¤ì •:
     - GroupShuffleSplit (test_size=0.2)
     - ê·¸ë£¹ ê¸°ì¤€: nominal_angle
     - train/test ë°œì‚¬ê° ê²¹ì¹¨: {'ìˆìŒ âš ï¸' if overlap else 'ì—†ìŒ âœ…'}
  
  ğŸ“‹ í…ŒìŠ¤íŠ¸ ë°œì‚¬ê°:
     {sorted(test_angles.tolist())}
  
  ğŸ¯ ê²°ê³¼:
     - ë°œì‚¬ê° ê·¸ë£¹ í‰ê°€ ì •í™•ë„: {accuracy * 100:.2f}%
  
  ğŸ’¡ í•´ì„:
     - ì´ í‰ê°€ëŠ” "í•™ìŠµí•˜ì§€ ì•Šì€ ë°œì‚¬ê°"ì—ì„œì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
     - ëœë¤ Split í‰ê°€ë³´ë‹¤ ë‚®ì€ ì •í™•ë„ê°€ ë‚˜ì˜¬ ìˆ˜ ìˆìœ¼ë©°, 
       ì´ëŠ” ëª¨ë¸ì´ íŠ¹ì • ë°œì‚¬ê°ì— ê³¼ì í•©ë˜ì§€ ì•Šì•˜ìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
""")
    
    # ---------------------------------------------------------------------
    # 7. ëª¨ë¸ ì €ì¥ (ê²Œì„ ì—°ë™ìš©)
    # ---------------------------------------------------------------------
    print("\n" + "=" * 70)
    print("ğŸ’¾ STEP 7: ëª¨ë¸ ì €ì¥")
    print("=" * 70)
    
    model_dir = Path("trained_models")
    model_dir.mkdir(exist_ok=True)
    
    # ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ (ê²Œì„ìš© ìµœì¢… ëª¨ë¸)
    print("ğŸ¯ ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ ì¤‘...")
    scaler_final = StandardScaler()
    X_all_scaled = scaler_final.fit_transform(features)
    
    model_final = RandomForestClassifier(
        n_estimators=100,
        max_depth=15,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42,
        n_jobs=-1
    )
    model_final.fit(X_all_scaled, labels)
    
    # ì €ì¥
    joblib.dump(model_final, model_dir / "rf_model.pkl")
    joblib.dump(scaler_final, model_dir / "scaler.pkl")
    joblib.dump(feature_names, model_dir / "feature_names.pkl")
    joblib.dump(missile_types, model_dir / "missile_types.pkl")
    
    print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ:")
    print(f"   - {model_dir / 'rf_model.pkl'}")
    print(f"   - {model_dir / 'scaler.pkl'}")
    print(f"   - {model_dir / 'feature_names.pkl'}")
    print(f"   - {model_dir / 'missile_types.pkl'}")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
